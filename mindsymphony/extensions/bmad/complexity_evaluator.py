"""
å¤æ‚åº¦è¯„ä¼°å¼•æ“
åŸºäº BMAD æ–¹æ³•è®ºï¼Œè‡ªåŠ¨è¯„ä¼°ä»»åŠ¡çš„å¤æ‚åº¦å¹¶æ¨èåˆé€‚çš„å·¥ä½œæµè·¯å¾„
"""

import re
from dataclasses import dataclass
from enum import Enum
from typing import Dict, List, Optional, Tuple
import json
import os


class DomainComplexity(Enum):
    SIMPLE = 1    # bugfix, docs, refactor
    MEDIUM = 3    # feature, api
    COMPLEX = 5   # architecture, service
    EXPERT = 8    # distributed, ai-model


class ScaleComplexity(Enum):
    TINY = 1      # <50 lines
    SMALL = 2     # 50-200 lines
    MEDIUM = 4    # 200-1000 lines
    LARGE = 7     # 1000+ lines


class ImpactScope(Enum):
    ISOLATED = 1   # å•ä¸€æ¨¡å—
    MODULE = 3     # å¤šä¸ªæ¨¡å—
    CROSS_TEAM = 5 # è·¨å›¢é˜Ÿ
    BREAKING = 7   # ç ´åæ€§å˜æ›´


@dataclass
class ComplexityScore:
    """å¤æ‚åº¦è¯„åˆ†ç»“æœ"""
    total_score: int           # æ€»åˆ† (1-10+)
    domain_score: int
    scale_score: int
    impact_score: int
    domain_type: str
    scale_type: str
    impact_type: str
    recommended_path: str      # "quick" | "full" | "party"
    confidence: float          # 0.0 - 1.0
    reasoning: List[str]       # è¯„åˆ†ç†ç”±

    def to_dict(self) -> Dict:
        return {
            "total_score": self.total_score,
            "domain_score": self.domain_score,
            "scale_score": self.scale_score,
            "impact_score": self.impact_score,
            "domain_type": self.domain_type,
            "scale_type": self.scale_type,
            "impact_type": self.impact_type,
            "recommended_path": self.recommended_path,
            "confidence": self.confidence,
            "reasoning": self.reasoning
        }


class ComplexityEvaluator:
    """
    å¤æ‚åº¦è¯„ä¼°å¼•æ“

    è¯„ä¼°ç»´åº¦:
    1. é¢†åŸŸå¤æ‚åº¦ (Domain) - æŠ€æœ¯é¢†åŸŸéš¾åº¦
    2. è§„æ¨¡å¤æ‚åº¦ (Scale) - ä»£ç é‡/æ–‡ä»¶æ•°
    3. å½±å“èŒƒå›´ (Impact) - å˜æ›´å½±å“é¢

    æ€»åˆ† = domain + scale + impact
    - 1-3: Quick Flow
    - 4-5: Full Planning
    - 6+: å»ºè®® Party Mode
    """

    # é¢†åŸŸå…³é”®è¯æ˜ å°„
    DOMAIN_KEYWORDS = {
        DomainComplexity.SIMPLE: [
            "fix", "bug", "typo", "doc", "comment", "rename", "format",
            "lint", "style", "cleanup", "refactor", "extract", "move",
            "update", "patch", "correct", "improve"
        ],
        DomainComplexity.MEDIUM: [
            "add", "feature", "endpoint", "component", "page", "route",
            "api", "function", "method", "class", "module", "service",
            "implement", "create", "build"
        ],
        DomainComplexity.COMPLEX: [
            "system", "platform", "architecture", "redesign", "migration",
            "refactor", "restructure", "redesign", "framework", "engine",
            "orchestration", "workflow", "pipeline"
        ],
        DomainComplexity.EXPERT: [
            "distributed", "consensus", "crypto", "blockchain", "ml-model",
            "ai-training", "kernel", "compiler", "database-engine",
            "real-time", "high-performance", "concurrent", "parallel"
        ]
    }

    # è§„æ¨¡å…³é”®è¯
    SCALE_KEYWORDS = {
        "files": {
            ScaleComplexity.TINY: ["one file", "single file", "å°æ–‡ä»¶"],
            ScaleComplexity.SMALL: ["few files", "couple files", "å‡ ä¸ªæ–‡ä»¶"],
            ScaleComplexity.MEDIUM: ["multiple files", "several files", "å¤šä¸ªæ–‡ä»¶"],
            ScaleComplexity.LARGE: ["many files", "across project", "æ•´ä¸ªé¡¹ç›®"]
        },
        "lines": {
            ScaleComplexity.TINY: ["few lines", "trivial", "ç®€å•å‡ è¡Œ"],
            ScaleComplexity.SMALL: ["small change", "å‡ åè¡Œ"],
            ScaleComplexity.MEDIUM: ["hundreds of lines", "å‡ ç™¾è¡Œ"],
            ScaleComplexity.LARGE: ["thousands of lines", "å¤§è§„æ¨¡", "ä¸Šåƒè¡Œ"]
        }
    }

    # å½±å“èŒƒå›´å…³é”®è¯
    IMPACT_KEYWORDS = {
        ImpactScope.ISOLATED: [
            "isolated", "single", "one place", "local", "internal",
            "private", "helper", "utility"
        ],
        ImpactScope.MODULE: [
            "module", "package", "component", "several places",
            "multiple locations", "related"
        ],
        ImpactScope.CROSS_TEAM: [
            "cross-team", "shared", "common", "public api",
            "interface", "contract", "dependency"
        ],
        ImpactScope.BREAKING: [
            "breaking", "deprecated", "major version", "incompatible",
            "fundamental", "core", "critical path"
        ]
    }

    # é˜ˆå€¼é…ç½®
    THRESHOLDS = {
        "quick_flow_max": 3,
        "full_flow_min": 4,
        "party_mode_min": 6
    }

    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–å¤æ‚åº¦è¯„ä¼°å™¨

        Args:
            config_path: å¯é€‰çš„é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self._compile_patterns()

    def _load_config(self, config_path: Optional[str]) -> Dict:
        """åŠ è½½é…ç½®"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}

    def _compile_patterns(self):
        """ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        self.domain_patterns = {}
        for domain, keywords in self.DOMAIN_KEYWORDS.items():
            pattern = r'\b(?:' + '|'.join(re.escape(kw) for kw in keywords) + r')\b'
            self.domain_patterns[domain] = re.compile(pattern, re.IGNORECASE)

    def evaluate(
        self,
        user_input: str,
        context: Optional[Dict] = None
    ) -> ComplexityScore:
        """
        è¯„ä¼°ç”¨æˆ·è¾“å…¥çš„å¤æ‚åº¦

        Args:
            user_input: ç”¨æˆ·æè¿°çš„ä»»åŠ¡
            context: å¯é€‰çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
                - codebase_stats: ä»£ç åº“ç»Ÿè®¡
                - recent_changes: æœ€è¿‘çš„å˜æ›´
                - user_history: ç”¨æˆ·å†å²åå¥½

        Returns:
            ComplexityScore: å¤æ‚åº¦è¯„åˆ†ç»“æœ
        """
        context = context or {}
        reasoning = []

        # 1. è¯„ä¼°é¢†åŸŸå¤æ‚åº¦
        domain_score, domain_type = self._evaluate_domain(user_input)
        reasoning.append(f"é¢†åŸŸè¯„ä¼°: {domain_type} (åˆ†æ•°: {domain_score})")

        # 2. è¯„ä¼°è§„æ¨¡å¤æ‚åº¦
        scale_score, scale_type = self._evaluate_scale(user_input, context)
        reasoning.append(f"è§„æ¨¡è¯„ä¼°: {scale_type} (åˆ†æ•°: {scale_score})")

        # 3. è¯„ä¼°å½±å“èŒƒå›´
        impact_score, impact_type = self._evaluate_impact(user_input, context)
        reasoning.append(f"å½±å“è¯„ä¼°: {impact_type} (åˆ†æ•°: {impact_score})")

        # è®¡ç®—æ€»åˆ†
        total_score = domain_score + scale_score + impact_score

        # 4. è°ƒæ•´å› ç´ 
        adjustments = self._apply_adjustments(user_input, context, total_score)
        if adjustments:
            total_score += adjustments["delta"]
            reasoning.extend(adjustments["reasons"])

        # ç¡®å®šæ¨èè·¯å¾„
        recommended_path = self._determine_path(total_score, context)

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(
            user_input, domain_score, scale_score, impact_score
        )

        return ComplexityScore(
            total_score=total_score,
            domain_score=domain_score,
            scale_score=scale_score,
            impact_score=impact_score,
            domain_type=domain_type,
            scale_type=scale_type,
            impact_type=impact_type,
            recommended_path=recommended_path,
            confidence=confidence,
            reasoning=reasoning
        )

    def _evaluate_domain(self, user_input: str) -> Tuple[int, str]:
        """è¯„ä¼°é¢†åŸŸå¤æ‚åº¦"""
        scores = {domain: 0 for domain in DomainComplexity}
        user_lower = user_input.lower()

        for domain, pattern in self.domain_patterns.items():
            matches = len(pattern.findall(user_input))
            scores[domain] = matches

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ˜æ˜¾ç®€å•çš„ä»»åŠ¡
        simple_indicators = ['typo', 'spell', 'é”™åˆ«å­—', 'æ‹¼å†™', 'æ ¼å¼', 'format', 'ç©ºæ ¼', 'space']
        if any(ind in user_lower for ind in simple_indicators):
            return DomainComplexity.SIMPLE.value, "simple"

        # æ‰¾å‡ºæœ€é«˜åˆ†çš„é¢†åŸŸ
        max_domain = max(scores, key=scores.get)
        max_score = scores[max_domain]

        if max_score == 0:
            # æ²¡æœ‰åŒ¹é…åˆ°å…³é”®è¯ï¼Œæ£€æŸ¥è¾“å…¥é•¿åº¦
            if len(user_input.split()) <= 5:
                return DomainComplexity.SIMPLE.value, "simple"
            return DomainComplexity.MEDIUM.value, "medium"

        return max_domain.value, max_domain.name.lower()

    def _evaluate_scale(self, user_input: str, context: Dict) -> Tuple[int, str]:
        """è¯„ä¼°è§„æ¨¡å¤æ‚åº¦"""
        user_lower = user_input.lower()

        # æ£€æŸ¥æ˜¯å¦æ˜¯æå°è§„æ¨¡ä»»åŠ¡
        tiny_indicators = ['typo', 'spell', 'format', 'rename', 'ç©ºæ ¼', 'æ‹¼å†™']
        if any(ind in user_lower for ind in tiny_indicators):
            return ScaleComplexity.TINY.value, "tiny"

        # æ£€æŸ¥æ˜¾å¼çš„è§„æ¨¡æè¿°
        for scale_type, keywords in self.SCALE_KEYWORDS["lines"].items():
            for keyword in keywords:
                if keyword.lower() in user_lower:
                    return scale_type.value, scale_type.name.lower()

        # åŸºäºä»£ç åº“ç»Ÿè®¡æ¨æ–­
        codebase_stats = context.get("codebase_stats", {})
        estimated_lines = codebase_stats.get("estimated_lines_changed", 0)

        if estimated_lines > 0:
            if estimated_lines < 50:
                return ScaleComplexity.TINY.value, "tiny"
            elif estimated_lines < 200:
                return ScaleComplexity.SMALL.value, "small"
            elif estimated_lines < 1000:
                return ScaleComplexity.MEDIUM.value, "medium"
            else:
                return ScaleComplexity.LARGE.value, "large"

        # é»˜è®¤æœ€å°è§„æ¨¡ (typoç­‰å°ä¿®æ”¹)
        words = len(user_input.split())
        if words <= 5:
            return ScaleComplexity.TINY.value, "tiny"

        return ScaleComplexity.SMALL.value, "small"

    def _evaluate_impact(self, user_input: str, context: Dict) -> Tuple[int, str]:
        """è¯„ä¼°å½±å“èŒƒå›´"""
        user_lower = user_input.lower()
        scores = {impact: 0 for impact in ImpactScope}

        # æ˜æ˜¾çš„å°ä¿®æ”¹ï¼Œç›´æ¥è¿”å›æœ€å°å½±å“
        trivial_indicators = ['typo', 'spell', 'format', 'comment', 'doc']
        if any(ind in user_lower for ind in trivial_indicators):
            return ImpactScope.ISOLATED.value, "isolated"

        for impact, keywords in self.IMPACT_KEYWORDS.items():
            for keyword in keywords:
                if keyword.lower() in user_lower:
                    scores[impact] += 1

        max_impact = max(scores, key=scores.get)
        max_score = scores[max_impact]

        if max_score == 0:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç ´åæ€§å˜æ›´å…³é”®è¯
            breaking_keywords = ["remove", "delete", "replace", "upgrade"]
            for kw in breaking_keywords:
                if kw in user_lower:
                    return ImpactScope.MODULE.value, "module"

            # é»˜è®¤æœ€å°å½±å“
            return ImpactScope.ISOLATED.value, "isolated"

        return max_impact.value, max_impact.name.lower()

    def _apply_adjustments(
        self,
        user_input: str,
        context: Dict,
        current_score: int
    ) -> Optional[Dict]:
        """åº”ç”¨è°ƒæ•´å› ç´ """
        adjustments = {"delta": 0, "reasons": []}

        # 1. ç”¨æˆ·æ˜ç¡®æŒ‡å®šå¤æ‚åº¦
        if any(kw in user_input.lower() for kw in ["ç®€å•", "quick", "fast", "easy"]):
            adjustments["delta"] -= 1
            adjustments["reasons"].append("ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºç®€å•ä»»åŠ¡ (-1)")

        if any(kw in user_input.lower() for kw in ["å¤æ‚", "difficult", "challenging", "å¤§è§„æ¨¡"]):
            adjustments["delta"] += 2
            adjustments["reasons"].append("ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºå¤æ‚ä»»åŠ¡ (+2)")

        # 2. è·¨é¢†åŸŸæŒ‡ç¤º
        domain_indicators = sum(1 for d in DomainComplexity if self._has_domain_keyword(user_input, d))
        if domain_indicators > 1:
            adjustments["delta"] += 1
            adjustments["reasons"].append("æ¶‰åŠå¤šä¸ªæŠ€æœ¯é¢†åŸŸ (+1)")

        # 3. å†å²æˆåŠŸç‡è°ƒæ•´ (å¦‚æœ Lightning æ•°æ®å¯ç”¨)
        user_history = context.get("user_history", {})
        similar_tasks = user_history.get("similar_tasks", [])
        if similar_tasks:
            avg_success = sum(t["success"] for t in similar_tasks) / len(similar_tasks)
            if avg_success < 0.5:
                adjustments["delta"] += 1
                adjustments["reasons"].append(f"ç±»ä¼¼ä»»åŠ¡å†å²æˆåŠŸç‡ä½ ({avg_success:.1%}) (+1)")

        return adjustments if adjustments["delta"] != 0 else None

    def _has_domain_keyword(self, user_input: str, domain: DomainComplexity) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æŸé¢†åŸŸçš„å…³é”®è¯"""
        pattern = self.domain_patterns.get(domain)
        if pattern:
            return bool(pattern.search(user_input))
        return False

    def _determine_path(self, total_score: int, context: Dict) -> str:
        """æ ¹æ®æ€»åˆ†ç¡®å®šæ¨èè·¯å¾„"""
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å¼ºåˆ¶æŒ‡å®šè·¯å¾„
        user_override = context.get("force_path")
        if user_override:
            return user_override

        # æ ¹æ®åˆ†æ•°æ¨è
        if total_score <= self.THRESHOLDS["quick_flow_max"]:
            return "quick"
        elif total_score >= self.THRESHOLDS["party_mode_min"]:
            return "party"
        else:
            return "full"

    def _calculate_confidence(
        self,
        user_input: str,
        domain_score: int,
        scale_score: int,
        impact_score: int
    ) -> float:
        """è®¡ç®—è¯„ä¼°ç½®ä¿¡åº¦"""
        # åŸºäºè¾“å…¥é•¿åº¦å’Œä¿¡æ¯é‡
        confidence = 0.5

        # è¾“å…¥è¶Šé•¿ï¼Œç½®ä¿¡åº¦è¶Šé«˜ (æœ€å¤š +0.2)
        words = len(user_input.split())
        confidence += min(words / 50, 0.2)

        # åŒ¹é…åˆ°å…³é”®è¯è¶Šå¤šï¼Œç½®ä¿¡åº¦è¶Šé«˜
        total_matches = domain_score + scale_score + impact_score
        confidence += min(total_matches / 10, 0.2)

        # å¦‚æœæ¶‰åŠå¤šä¸ªç»´åº¦ï¼Œç½®ä¿¡åº¦æ›´é«˜
        dimensions_with_signal = sum([
            1 if domain_score > 0 else 0,
            1 if scale_score > 0 else 0,
            1 if impact_score > 0 else 0
        ])
        confidence += (dimensions_with_signal - 1) * 0.05

        return min(confidence, 1.0)

    def explain_decision(self, score: ComplexityScore) -> str:
        """ç”Ÿæˆå†³ç­–è§£é‡Šæ–‡æœ¬"""
        explanation = f"""
## å¤æ‚åº¦è¯„ä¼°æŠ¥å‘Š

**æ€»è¯„åˆ†**: {score.total_score}/10

### ç»´åº¦åˆ†æ
| ç»´åº¦ | çº§åˆ« | åˆ†æ•° |
|------|------|------|
| é¢†åŸŸå¤æ‚åº¦ | {score.domain_type} | {score.domain_score} |
| è§„æ¨¡å¤æ‚åº¦ | {score.scale_type} | {score.scale_score} |
| å½±å“èŒƒå›´ | {score.impact_type} | {score.impact_score} |

### è¯„ä¼°ç†ç”±
"""
        for reason in score.reasoning:
            explanation += f"- {reason}\n"

        explanation += f"""
### æ¨èå·¥ä½œæµ
**{self._get_path_name(score.recommended_path)}**

ç½®ä¿¡åº¦: {score.confidence:.0%}
"""
        return explanation

    def _get_path_name(self, path: str) -> str:
        """è·å–è·¯å¾„åç§°"""
        names = {
            "quick": "âš¡ Quick Flow (å¿«é€Ÿæµç¨‹)",
            "full": "ğŸ” Full Planning (å®Œæ•´è§„åˆ’)",
            "party": "ğŸ‰ Party Mode (å¤šAgentåä½œ)"
        }
        return names.get(path, "Unknown")


# ä¾¿æ·å‡½æ•°
def evaluate_complexity(user_input: str, context: Optional[Dict] = None) -> ComplexityScore:
    """ä¾¿æ·å‡½æ•°ï¼šè¯„ä¼°å¤æ‚åº¦"""
    evaluator = ComplexityEvaluator()
    return evaluator.evaluate(user_input, context)
