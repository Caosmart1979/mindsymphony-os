"""
Skill DNA System
ä¸ªäººæŠ€èƒ½DNA - è¿½è¸ªç”¨æˆ·ä¸“é•¿ã€åå¥½å’Œæ¼”åŒ–

åŠŸèƒ½:
- ç”¨æˆ·ç”»åƒå»ºæ¨¡
- GitHubè¡Œä¸ºåˆ†æ
- æŠ€èƒ½ä½¿ç”¨æ¨¡å¼è¯†åˆ«
- ä¸ªæ€§åŒ–æ¨è
"""

import json
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Optional, Any
from datetime import datetime
from pathlib import Path
from collections import defaultdict


@dataclass
class UserProfile:
    """ç”¨æˆ·ç”»åƒ"""
    user_id: str
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    updated_at: str = field(default_factory=lambda: datetime.now().isoformat())

    # ä¸“é•¿é¢†åŸŸ (domain -> proficiency 0-1)
    expertise_domains: Dict[str, float] = field(default_factory=dict)

    # åå¥½æ¨¡å¼
    preferred_patterns: List[str] = field(default_factory=list)

    # æŠ€èƒ½åå¥½
    skill_preferences: Dict[str, Any] = field(default_factory=lambda: {
        'complexity': 'balanced',  # simple/detailed/balanced
        'style': 'pragmatic',      # academic/pragmatic/creative
        'depth': 'moderate'        # quick/moderate/thorough
    })

    # GitHubæ•°æ®æº
    github_sources: Dict[str, List[str]] = field(default_factory=lambda: {
        'starred_repos': [],
        'contributed_repos': [],
        'frequent_refs': [],
        'code_snippets': []
    })

    # å­¦ä¹ å†å²
    learning_history: List[Dict] = field(default_factory=list)

    def to_dict(self) -> Dict:
        return asdict(self)

    @classmethod
    def from_dict(cls, data: Dict) -> 'UserProfile':
        return cls(**data)


@dataclass
class SkillUsagePattern:
    """æŠ€èƒ½ä½¿ç”¨æ¨¡å¼"""
    skill_id: str
    skill_name: str
    first_used: str
    last_used: str
    use_count: int = 0
    success_count: int = 0
    avg_success_rate: float = 0.0
    context_tags: List[str] = field(default_factory=list)


class SkillDNA:
    """
    ä¸ªäººæŠ€èƒ½DNAç³»ç»Ÿ

    è¿½è¸ªç”¨æˆ·çš„æŠ€èƒ½ä¸“é•¿ã€ä½¿ç”¨æ¨¡å¼å’Œå­¦ä¹ åå¥½
    """

    def __init__(self, user_id: str, storage_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–æŠ€èƒ½DNA

        Args:
            user_id: ç”¨æˆ·ID
            storage_dir: å­˜å‚¨ç›®å½•
        """
        self.user_id = user_id
        self.storage_dir = Path(storage_dir or f'~/.mindsymphony/skill_dna/{user_id}')
        self.storage_dir = Path(self.storage_dir).expanduser()
        self.storage_dir.mkdir(parents=True, exist_ok=True)

        # åŠ è½½æˆ–åˆ›å»ºç”¨æˆ·ç”»åƒ
        self.profile = self._load_profile()

        # æŠ€èƒ½ä½¿ç”¨æ¨¡å¼
        self.usage_patterns: Dict[str, SkillUsagePattern] = {}
        self._load_usage_patterns()

    def analyze_github_profile(self, github_username: str) -> Dict:
        """
        åˆ†æGitHubç”¨æˆ·æ¡£æ¡ˆ

        æå–starred reposã€è´¡çŒ®å†å²ç­‰

        Args:
            github_username: GitHubç”¨æˆ·å

        Returns:
            åˆ†æç»“æœ
        """
        print(f"ğŸ” åˆ†æGitHubæ¡£æ¡ˆ: {github_username}")

        # æ¨¡æ‹ŸGitHubåˆ†æ (å®é™…å®ç°ä¼šè°ƒç”¨GitHub API)
        analysis = {
            'starred_repos': [
                'microsoft/TypeScript',
                'facebook/react',
                'bmad-code-org/BMAD-METHOD'
            ],
            'top_languages': ['Python', 'TypeScript', 'JavaScript'],
            'interests': ['architecture', 'methodology', 'AI'],
            'contributions': 150
        }

        # æ›´æ–°ç”¨æˆ·ç”»åƒ
        self._update_from_github_analysis(analysis)

        return analysis

    def record_skill_usage(
        self,
        skill_id: str,
        skill_name: str,
        success: bool,
        context: Optional[Dict] = None
    ):
        """
        è®°å½•æŠ€èƒ½ä½¿ç”¨æƒ…å†µ

        Args:
            skill_id: æŠ€èƒ½ID
            skill_name: æŠ€èƒ½åç§°
            success: æ˜¯å¦æˆåŠŸ
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        context = context or {}
        now = datetime.now().isoformat()

        if skill_id not in self.usage_patterns:
            self.usage_patterns[skill_id] = SkillUsagePattern(
                skill_id=skill_id,
                skill_name=skill_name,
                first_used=now,
                last_used=now,
                use_count=0,
                success_count=0,
                context_tags=context.get('tags', [])
            )

        pattern = self.usage_patterns[skill_id]
        pattern.last_used = now
        pattern.use_count += 1

        if success:
            pattern.success_count += 1

        # æ›´æ–°æˆåŠŸç‡
        pattern.avg_success_rate = pattern.success_count / pattern.use_count

        # æ·»åŠ ä¸Šä¸‹æ–‡æ ‡ç­¾
        for tag in context.get('tags', []):
            if tag not in pattern.context_tags:
                pattern.context_tags.append(tag)

        self._save_usage_patterns()

        # æ›´æ–°ä¸“é•¿é¢†åŸŸ
        self._update_expertise_from_usage(skill_id, success)

    def get_expertise_report(self) -> Dict:
        """
        ç”Ÿæˆä¸“é•¿æŠ¥å‘Š

        Returns:
            ä¸“é•¿é¢†åŸŸåˆ†ææŠ¥å‘Š
        """
        report = {
            'user_id': self.user_id,
            'generated_at': datetime.now().isoformat(),
            'expertise_domains': self.profile.expertise_domains,
            'top_skills': self._get_top_skills(10),
            'learning_velocity': self._calculate_learning_velocity(),
            'skill_diversity': len(self.usage_patterns),
            'success_rate': self._calculate_overall_success_rate()
        }

        return report

    def recommend_learning_path(
        self,
        target_domain: str,
        current_skills: Optional[List[str]] = None
    ) -> List[Dict]:
        """
        æ¨èå­¦ä¹ è·¯å¾„

        Args:
            target_domain: ç›®æ ‡é¢†åŸŸ
            current_skills: å½“å‰æŠ€èƒ½åˆ—è¡¨

        Returns:
            æ¨èçš„å­¦ä¹ è·¯å¾„
        """
        current_skills = current_skills or []

        # åŸºäºç›®æ ‡é¢†åŸŸå’Œå½“å‰ä¸“é•¿æ¨è
        recommendations = []

        # 1. åŸºç¡€æŠ€èƒ½ (å¦‚æœä¸“é•¿åˆ†æ•°ä½)
        if self.profile.expertise_domains.get(target_domain, 0) < 0.3:
            recommendations.append({
                'type': 'foundation',
                'name': f'{target_domain}-fundamentals',
                'priority': 'high',
                'reason': 'éœ€è¦å…ˆæŒæ¡åŸºç¡€çŸ¥è¯†'
            })

        # 2. è¿›é˜¶æŠ€èƒ½
        if 0.3 <= self.profile.expertise_domains.get(target_domain, 0) < 0.7:
            recommendations.append({
                'type': 'advanced',
                'name': f'{target_domain}-patterns',
                'priority': 'medium',
                'reason': 'å¯ä»¥å­¦ä¹ é«˜çº§æ¨¡å¼'
            })

        # 3. ç›¸å…³é¢†åŸŸ
        related_domains = self._find_related_domains(target_domain)
        for domain in related_domains[:2]:
            recommendations.append({
                'type': 'related',
                'name': f'{domain}-integration',
                'priority': 'low',
                'reason': f'æ‰©å±•ç›¸å…³é¢†åŸŸ: {domain}'
            })

        return recommendations

    def detect_skill_gaps(self, required_skills: List[str]) -> List[str]:
        """
        æ£€æµ‹æŠ€èƒ½ç¼ºå£

        Args:
            required_skills: éœ€è¦çš„æŠ€èƒ½åˆ—è¡¨

        Returns:
            ç¼ºå¤±çš„æŠ€èƒ½åˆ—è¡¨
        """
        gaps = []

        for skill in required_skills:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ­¤æŠ€èƒ½
            found = False
            for pattern in self.usage_patterns.values():
                if pattern.skill_name.lower() == skill.lower():
                    # æ£€æŸ¥ç†Ÿç»ƒåº¦
                    if pattern.avg_success_rate < 0.5:
                        gaps.append(f'{skill} (éœ€è¦æé«˜ç†Ÿç»ƒåº¦)')
                    found = True
                    break

            if not found:
                gaps.append(skill)

        return gaps

    def personalize_skill_content(
        self,
        skill_content: str,
        skill_type: str
    ) -> str:
        """
        ä¸ªæ€§åŒ–æŠ€èƒ½å†…å®¹

        æ ¹æ®ç”¨æˆ·DNAè°ƒæ•´æŠ€èƒ½å†…å®¹

        Args:
            skill_content: åŸå§‹æŠ€èƒ½å†…å®¹
            skill_type: æŠ€èƒ½ç±»å‹

        Returns:
            ä¸ªæ€§åŒ–åçš„å†…å®¹
        """
        preferences = self.profile.skill_preferences

        # æ ¹æ®åå¥½è°ƒæ•´
        if preferences['complexity'] == 'simple':
            # ç®€åŒ–å†…å®¹ï¼Œæå–å…³é”®è¦ç‚¹
            skill_content = self._simplify_content(skill_content)
        elif preferences['complexity'] == 'detailed':
            # æ·»åŠ æ›´å¤šç»†èŠ‚
            skill_content = self._enrich_content(skill_content)

        if preferences['style'] == 'academic':
            # æ·»åŠ ç†è®ºèƒŒæ™¯
            skill_content = self._add_theory_background(skill_content)

        return skill_content

    def export_dna_profile(self) -> Dict:
        """
        å¯¼å‡ºDNAæ¡£æ¡ˆ

        Returns:
            å®Œæ•´çš„DNAæ¡£æ¡ˆ
        """
        return {
            'profile': self.profile.to_dict(),
            'usage_patterns': {
                sid: asdict(pattern)
                for sid, pattern in self.usage_patterns.items()
            },
            'statistics': {
                'total_skills_used': len(self.usage_patterns),
                'avg_success_rate': self._calculate_overall_success_rate(),
                'expertise_areas': list(self.profile.expertise_domains.keys())
            }
        }

    def _load_profile(self) -> UserProfile:
        """åŠ è½½ç”¨æˆ·ç”»åƒ"""
        profile_path = self.storage_dir / 'profile.json'

        if profile_path.exists():
            try:
                with open(profile_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                return UserProfile.from_dict(data)
            except Exception as e:
                print(f"[SkillDNA] åŠ è½½ç”»åƒå¤±è´¥: {e}")

        # åˆ›å»ºæ–°ç”»åƒ
        return UserProfile(user_id=self.user_id)

    def _save_profile(self):
        """ä¿å­˜ç”¨æˆ·ç”»åƒ"""
        profile_path = self.storage_dir / 'profile.json'
        self.profile.updated_at = datetime.now().isoformat()

        with open(profile_path, 'w', encoding='utf-8') as f:
            json.dump(self.profile.to_dict(), f, ensure_ascii=False, indent=2)

    def _load_usage_patterns(self):
        """åŠ è½½ä½¿ç”¨æ¨¡å¼"""
        patterns_path = self.storage_dir / 'usage_patterns.json'

        if patterns_path.exists():
            try:
                with open(patterns_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                for sid, pattern_data in data.items():
                    self.usage_patterns[sid] = SkillUsagePattern(**pattern_data)
            except Exception as e:
                print(f"[SkillDNA] åŠ è½½ä½¿ç”¨æ¨¡å¼å¤±è´¥: {e}")

    def _save_usage_patterns(self):
        """ä¿å­˜ä½¿ç”¨æ¨¡å¼"""
        patterns_path = self.storage_dir / 'usage_patterns.json'

        data = {
            sid: asdict(pattern)
            for sid, pattern in self.usage_patterns.items()
        }

        with open(patterns_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def _update_from_github_analysis(self, analysis: Dict):
        """ä»GitHubåˆ†ææ›´æ–°ç”»åƒ"""
        # æ›´æ–°GitHubæº
        self.profile.github_sources['starred_repos'] = analysis.get('starred_repos', [])

        # æ¨æ–­ä¸“é•¿é¢†åŸŸ
        for lang in analysis.get('top_languages', []):
            domain = self._language_to_domain(lang)
            current = self.profile.expertise_domains.get(domain, 0)
            self.profile.expertise_domains[domain] = min(current + 0.2, 1.0)

        # æ›´æ–°å…´è¶£é¢†åŸŸ
        for interest in analysis.get('interests', []):
            if interest not in self.profile.expertise_domains:
                self.profile.expertise_domains[interest] = 0.3

        self._save_profile()

    def _language_to_domain(self, language: str) -> str:
        """ç¼–ç¨‹è¯­è¨€æ˜ å°„åˆ°é¢†åŸŸ"""
        mapping = {
            'Python': 'data_science',
            'JavaScript': 'web_development',
            'TypeScript': 'web_development',
            'Java': 'enterprise',
            'Go': 'systems',
            'Rust': 'systems',
        }
        return mapping.get(language, 'general_programming')

    def _update_expertise_from_usage(self, skill_id: str, success: bool):
        """ä»ä½¿ç”¨æ›´æ–°ä¸“é•¿"""
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ ¹æ®æŠ€èƒ½ç±»å‹æ›´æ–°ç›¸åº”é¢†åŸŸ
        pass

    def _get_top_skills(self, limit: int) -> List[Dict]:
        """è·å–æœ€å¸¸ç”¨çš„æŠ€èƒ½"""
        sorted_patterns = sorted(
            self.usage_patterns.values(),
            key=lambda p: p.use_count,
            reverse=True
        )

        return [
            {
                'skill_id': p.skill_id,
                'skill_name': p.skill_name,
                'use_count': p.use_count,
                'success_rate': p.avg_success_rate
            }
            for p in sorted_patterns[:limit]
        ]

    def _calculate_learning_velocity(self) -> float:
        """è®¡ç®—å­¦ä¹ é€Ÿåº¦"""
        if len(self.usage_patterns) < 2:
            return 0.0

        # åŸºäºæŠ€èƒ½å¢é•¿æ›²çº¿è®¡ç®—
        return len(self.usage_patterns) / 10.0  # ç®€åŒ–è®¡ç®—

    def _calculate_overall_success_rate(self) -> float:
        """è®¡ç®—æ€»ä½“æˆåŠŸç‡"""
        if not self.usage_patterns:
            return 0.0

        total_success = sum(p.success_count for p in self.usage_patterns.values())
        total_usage = sum(p.use_count for p in self.usage_patterns.values())

        return total_success / total_usage if total_usage > 0 else 0.0

    def _find_related_domains(self, domain: str) -> List[str]:
        """æŸ¥æ‰¾ç›¸å…³é¢†åŸŸ"""
        # é¢†åŸŸå…³ç³»æ˜ å°„
        relations = {
            'web_development': ['frontend', 'backend', 'devops'],
            'data_science': ['machine_learning', 'statistics', 'visualization'],
            'systems': ['networking', 'security', 'performance'],
        }

        return relations.get(domain, [])

    def _simplify_content(self, content: str) -> str:
        """ç®€åŒ–å†…å®¹"""
        # æå–å…³é”®éƒ¨åˆ†
        lines = content.split('\n')
        key_lines = []

        for line in lines:
            if line.startswith('#') or line.startswith('- ') or line.startswith('1.'):
                key_lines.append(line)

        return '\n'.join(key_lines[:20]) if key_lines else content

    def _enrich_content(self, content: str) -> str:
        """ä¸°å¯Œå†…å®¹"""
        # æ·»åŠ æ›´å¤šè§£é‡Šå’Œç¤ºä¾‹
        return content + "\n\n## æ·±å…¥é˜…è¯»\n\n- è¯¦ç»†æ–‡æ¡£é“¾æ¥\n- ç›¸å…³è®ºæ–‡\n- æ¡ˆä¾‹ç ”ç©¶"

    def _add_theory_background(self, content: str) -> str:
        """æ·»åŠ ç†è®ºèƒŒæ™¯"""
        theory_section = """
## ç†è®ºåŸºç¡€

æ­¤æ–¹æ³•åŸºäºä»¥ä¸‹ç†è®ºï¼š
- è®¤çŸ¥è´Ÿè·ç†è®º
- ä¸“å®¶å®è·µç ”ç©¶
- è½¯ä»¶å·¥ç¨‹åŸç†

### ç ”ç©¶èƒŒæ™¯

[ç†è®ºè§£é‡Š...]
"""
        return theory_section + "\n\n" + content
