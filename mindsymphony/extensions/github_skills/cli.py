"""
GitHub Skills CLI
å‘½ä»¤è¡Œæ¥å£ - æä¾›ä¾¿æ·çš„å‘½ä»¤è¡Œå·¥å…·

Usage:
    python -m mindsymphony.extensions.github_skills.cli distill <repo_url>
    python -m mindsymphony.extensions.github_skills.cli search <query>
    python -m mindsymphony.extensions.github_skills.cli generate <task_description>
    python -m mindsymphony.extensions.github_skills.cli profile <github_username>
    python -m mindsymphony.extensions.github_skills.cli recommend
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Optional

from .github_skill_distiller import GitHubSkillDistiller
from .skill_knowledge_graph import SkillKnowledgeGraph
from .skill_dna import SkillDNA
from .dynamic_skill_generator import DynamicSkillGenerator, GenerationRequest


def cmd_distill(args):
    """è’¸é¦GitHubä»“åº“ä¸ºæŠ€èƒ½"""
    print(f"ğŸ”¬ æ­£åœ¨è’¸é¦: {args.repo}")

    distiller = GitHubSkillDistiller()
    result = distiller.distill(
        args.repo,
        extract_patterns=args.extract_patterns,
        include_code_examples=args.include_code,
        personalize=args.personalize
    )

    # ä¿å­˜æŠ€èƒ½æ–‡ä»¶
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    skill_file = output_dir / f"{result.skill_name}.md"
    with open(skill_file, 'w', encoding='utf-8') as f:
        f.write(result.skill_content)

    # ä¿å­˜å…ƒæ•°æ®
    meta_file = output_dir / f"{result.skill_name}.json"
    with open(meta_file, 'w', encoding='utf-8') as f:
        json.dump(result.metadata, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… è’¸é¦å®Œæˆ!")
    print(f"ğŸ“„ æŠ€èƒ½æ–‡ä»¶: {skill_file}")
    print(f"ğŸ“Š ç½®ä¿¡åº¦: {result.confidence:.1%}")
    print(f"ğŸ”– æå–æ¨¡å¼: {len(result.patterns)} ä¸ª")

    return result


def cmd_search(args):
    """æœç´¢æŠ€èƒ½çŸ¥è¯†å›¾è°±"""
    print(f"ğŸ” æœç´¢: {args.query}")

    graph = SkillKnowledgeGraph()
    results = graph.search(args.query, limit=args.limit)

    if not results:
        print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æŠ€èƒ½")
        return

    print(f"\nğŸ“Š æ‰¾åˆ° {len(results)} ä¸ªæŠ€èƒ½:\n")

    for i, skill in enumerate(results, 1):
        print(f"{i}. {skill.name}")
        print(f"   æ¥æº: {skill.source}")
        print(f"   ç±»å‹: {skill.type}")
        print(f"   æ ‡ç­¾: {', '.join(skill.tags) if skill.tags else 'æ— '}")
        print(f"   æè¿°: {skill.description[:100]}..." if skill.description else "")
        print()


def cmd_generate(args):
    """åŠ¨æ€ç”ŸæˆæŠ€èƒ½"""
    print(f"ğŸ¯ ç”Ÿæˆä»»åŠ¡æŠ€èƒ½: {args.task[:50]}...")

    generator = DynamicSkillGenerator()

    request = GenerationRequest(
        task_description=args.task,
        required_capabilities=args.capabilities or [],
        preferred_sources=args.sources or []
    )

    skill = generator.generate(request, persist=args.persist)

    # ä¿å­˜æŠ€èƒ½æ–‡ä»¶
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    skill_file = output_dir / f"{skill.skill_id}.md"
    with open(skill_file, 'w', encoding='utf-8') as f:
        f.write(skill.content)

    print(f"\nâœ… æŠ€èƒ½ç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“„ æŠ€èƒ½æ–‡ä»¶: {skill_file}")
    print(f"ğŸ“Š ç½®ä¿¡åº¦: {skill.confidence:.1%}")
    print(f"ğŸ”— å‚è€ƒæ¥æº: {len(skill.sources)} ä¸ªé¡¹ç›®")

    if skill.confidence < 0.6:
        print("\nâš ï¸  ç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®äººå·¥å®¡æ ¸åä½¿ç”¨")


def cmd_profile(args):
    """åˆ†æGitHubç”¨æˆ·æ¡£æ¡ˆ"""
    print(f"ğŸ‘¤ åˆ†æGitHubç”¨æˆ·: {args.username}")

    dna = SkillDNA(user_id=args.user_id or args.username)
    analysis = dna.analyze_github_profile(args.username)

    print(f"\nğŸ“Š åˆ†æç»“æœ:\n")
    print(f"Starred Repos: {len(analysis.get('starred_repos', []))}")
    print(f"Top Languages: {', '.join(analysis.get('top_languages', []))}")
    print(f"Interests: {', '.join(analysis.get('interests', []))}")
    print(f"Contributions: {analysis.get('contributions', 0)}")

    # ç”Ÿæˆä¸“é•¿æŠ¥å‘Š
    report = dna.get_expertise_report()

    print(f"\nğŸ¯ ä¸“é•¿é¢†åŸŸ:")
    for domain, score in report.get('expertise_domains', {}).items():
        bar = 'â–ˆ' * int(score * 10) + 'â–‘' * (10 - int(score * 10))
        print(f"  {domain:20s} [{bar}] {score:.0%}")

    if args.output:
        output_file = Path(args.output)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: {output_file}")


def cmd_recommend(args):
    """æ¨èå­¦ä¹ è·¯å¾„"""
    print(f"ğŸ“š ç”Ÿæˆå­¦ä¹ æ¨è...")

    dna = SkillDNA(user_id=args.user_id or 'default')

    if args.domain:
        recommendations = dna.recommend_learning_path(args.domain)
        print(f"\nğŸ¯ {args.domain} å­¦ä¹ è·¯å¾„æ¨è:\n")
    else:
        # åŸºäºå½“å‰ä¸“é•¿æ¨è
        report = dna.get_expertise_report()
        domains = list(report.get('expertise_domains', {}).keys())

        if not domains:
            print("âŒ æš‚æ— ä¸“é•¿æ•°æ®ï¼Œè¯·å…ˆåˆ†æGitHubæ¡£æ¡ˆ")
            return

        target_domain = domains[0]
        recommendations = dna.recommend_learning_path(target_domain)
        print(f"\nğŸ¯ åŸºäºæ‚¨çš„ä¸“é•¿ï¼Œæ¨èå­¦ä¹ : {target_domain}\n")

    for i, rec in enumerate(recommendations, 1):
        priority_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(rec['priority'], 'âšª')
        print(f"{i}. {priority_emoji} {rec['name']}")
        print(f"   ç±»å‹: {rec['type']}")
        print(f"   åŸå› : {rec['reason']}")
        print()


def cmd_stats(args):
    """æ˜¾ç¤ºæŠ€èƒ½åº“ç»Ÿè®¡"""
    print("ğŸ“Š MindSymphony GitHubæŠ€èƒ½åº“ç»Ÿè®¡\n")

    # çŸ¥è¯†å›¾è°±ç»Ÿè®¡
    graph = SkillKnowledgeGraph()
    graph_stats = graph.get_stats()

    print("çŸ¥è¯†å›¾è°±:")
    print(f"  æŠ€èƒ½èŠ‚ç‚¹: {graph_stats['total_nodes']}")
    print(f"  å…³ç³»æ•°é‡: {graph_stats['total_relations']}")
    print(f"  å¹³å‡ä½¿ç”¨: {graph_stats['avg_usage']:.1f}")

    if graph_stats['relation_types']:
        print("\n  å…³ç³»ç±»å‹åˆ†å¸ƒ:")
        for rel_type, count in graph_stats['relation_types'].items():
            print(f"    {rel_type}: {count}")

    # DNAç»Ÿè®¡
    dna = SkillDNA(user_id=args.user_id or 'default')
    report = dna.get_expertise_report()

    print(f"\nä¸ªäººæŠ€èƒ½DNA:")
    print(f"  æŠ€èƒ½å¤šæ ·æ€§: {report.get('skill_diversity', 0)}")
    print(f"  æ€»ä½“æˆåŠŸç‡: {report.get('success_rate', 0):.1%}")
    print(f"  å­¦ä¹ é€Ÿåº¦: {report.get('learning_velocity', 0):.1f}")

    if report.get('top_skills'):
        print("\n  å¸¸ç”¨æŠ€èƒ½:")
        for skill in report['top_skills'][:5]:
            print(f"    - {skill['skill_name']}: {skill['use_count']}æ¬¡ ({skill['success_rate']:.0%}æˆåŠŸç‡)")


def cmd_export(args):
    """å¯¼å‡ºæŠ€èƒ½å›¾è°±"""
    print(f"ğŸ“¤ å¯¼å‡ºæŠ€èƒ½å›¾è°±...")

    graph = SkillKnowledgeGraph()

    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    if args.format == 'dot':
        graph.export_to_dot(str(output_path))
        print(f"âœ… å·²å¯¼å‡ºä¸ºGraphVizæ ¼å¼: {output_path}")
        print("ğŸ’¡ ä½¿ç”¨ 'dot -Tpng {output_path} -o graph.png' ç”Ÿæˆå›¾ç‰‡")
    else:
        # å¯¼å‡ºä¸ºJSON
        data = {
            'nodes': [s.to_dict() for s in graph.nodes.values()],
            'relations': [r.to_dict() for r in graph.relations],
        }
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… å·²å¯¼å‡ºä¸ºJSON: {output_path}")


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description='MindSymphony GitHub Skills - å°†GitHubå‹ç¼©æˆä½ çš„è¶…çº§æŠ€èƒ½åº“',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è’¸é¦GitHubä»“åº“
  python -m mindsymphony.extensions.github_skills.cli distill microsoft/ai-examples

  # æœç´¢æŠ€èƒ½
  python -m mindsymphony.extensions.github_skills.cli search "machine learning"

  # åŠ¨æ€ç”ŸæˆæŠ€èƒ½
  python -m mindsymphony.extensions.github_skills.cli generate "åˆ†æç”Ÿç‰©ä¿¡æ¯å­¦æ•°æ®"

  # åˆ†æGitHubæ¡£æ¡ˆ
  python -m mindsymphony.extensions.github_skills.cli profile octocat

  # æŸ¥çœ‹ç»Ÿè®¡
  python -m mindsymphony.extensions.github_skills.cli stats
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # distillå‘½ä»¤
    distill_parser = subparsers.add_parser('distill', help='è’¸é¦GitHubä»“åº“ä¸ºæŠ€èƒ½')
    distill_parser.add_argument('repo', help='ä»“åº“æ ‡è¯† (å¦‚: owner/repo)')
    distill_parser.add_argument('--output', '-o', default='./generated_skills', help='è¾“å‡ºç›®å½•')
    distill_parser.add_argument('--extract-patterns', action='store_true', help='æå–ä»£ç æ¨¡å¼')
    distill_parser.add_argument('--include-code', action='store_true', help='åŒ…å«ä»£ç ç¤ºä¾‹')
    distill_parser.add_argument('--personalize', action='store_true', help='ä¸ªæ€§åŒ–ç”Ÿæˆ')
    distill_parser.set_defaults(func=cmd_distill)

    # searchå‘½ä»¤
    search_parser = subparsers.add_parser('search', help='æœç´¢æŠ€èƒ½çŸ¥è¯†å›¾è°±')
    search_parser.add_argument('query', help='æœç´¢å…³é”®è¯')
    search_parser.add_argument('--limit', '-l', type=int, default=10, help='è¿”å›æ•°é‡')
    search_parser.set_defaults(func=cmd_search)

    # generateå‘½ä»¤
    generate_parser = subparsers.add_parser('generate', help='åŠ¨æ€ç”ŸæˆæŠ€èƒ½')
    generate_parser.add_argument('task', help='ä»»åŠ¡æè¿°')
    generate_parser.add_argument('--output', '-o', default='./generated_skills', help='è¾“å‡ºç›®å½•')
    generate_parser.add_argument('--capabilities', '-c', nargs='+', help='å¿…éœ€èƒ½åŠ›')
    generate_parser.add_argument('--sources', '-s', nargs='+', help='é¦–é€‰æ¥æº')
    generate_parser.add_argument('--persist', action='store_true', help='æŒä¹…åŒ–åˆ°çŸ¥è¯†å›¾è°±')
    generate_parser.set_defaults(func=cmd_generate)

    # profileå‘½ä»¤
    profile_parser = subparsers.add_parser('profile', help='åˆ†æGitHubç”¨æˆ·æ¡£æ¡ˆ')
    profile_parser.add_argument('username', help='GitHubç”¨æˆ·å')
    profile_parser.add_argument('--user-id', help='ç”¨æˆ·ID')
    profile_parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶')
    profile_parser.set_defaults(func=cmd_profile)

    # recommendå‘½ä»¤
    recommend_parser = subparsers.add_parser('recommend', help='æ¨èå­¦ä¹ è·¯å¾„')
    recommend_parser.add_argument('--domain', '-d', help='ç›®æ ‡é¢†åŸŸ')
    recommend_parser.add_argument('--user-id', help='ç”¨æˆ·ID')
    recommend_parser.set_defaults(func=cmd_recommend)

    # statså‘½ä»¤
    stats_parser = subparsers.add_parser('stats', help='æ˜¾ç¤ºæŠ€èƒ½åº“ç»Ÿè®¡')
    stats_parser.add_argument('--user-id', help='ç”¨æˆ·ID')
    stats_parser.set_defaults(func=cmd_stats)

    # exportå‘½ä»¤
    export_parser = subparsers.add_parser('export', help='å¯¼å‡ºæŠ€èƒ½å›¾è°±')
    export_parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºæ–‡ä»¶')
    export_parser.add_argument('--format', choices=['json', 'dot'], default='json', help='å¯¼å‡ºæ ¼å¼')
    export_parser.set_defaults(func=cmd_export)

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    try:
        args.func(args)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()
