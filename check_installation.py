"""
æ£€æŸ¥ videocut ç¯å¢ƒå®‰è£…çŠ¶æ€
"""

import os
from pathlib import Path

def check_installation():
    print("=" * 60)
    print("ğŸ“¦ videocut ç¯å¢ƒå®‰è£…çŠ¶æ€æ£€æŸ¥")
    print("=" * 60)

    # æ£€æŸ¥ FunASR æ¨¡å‹
    print("\nğŸ” æ£€æŸ¥ FunASR æ¨¡å‹ (~2GB)")
    modelscope_cache = Path.home() / ".cache" / "modelscope" / "hub" / "models"

    models = {
        "paraformer-zh": "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
        "fsmn-vad": "iic/speech_fsmn_vad_zh-cn-16k-common-pytorch",
        "punc_ct": "iic/punc_ct-transformer_cn-en-common-vocab471067-large"
    }

    for name, path in models.items():
        model_path = modelscope_cache / path
        if model_path.exists():
            # è®¡ç®—å¤§å°
            size = sum(f.stat().st_size for f in model_path.rglob('*') if f.is_file())
            size_mb = size / (1024 * 1024)
            print(f"  âœ… {name}: {size_mb:.1f} MB")
        else:
            print(f"  â³ {name}: ä¸‹è½½ä¸­...")

    # æ£€æŸ¥ Whisper æ¨¡å‹
    print("\nğŸ” æ£€æŸ¥ Whisper æ¨¡å‹ (~2.9GB)")
    whisper_cache = Path.home() / ".cache" / "whisper"
    whisper_model = whisper_cache / "large-v3.pt"

    if whisper_model.exists():
        size_mb = whisper_model.stat().st_size / (1024 * 1024)
        print(f"  âœ… large-v3: {size_mb:.1f} MB")
    else:
        print(f"  â³ large-v3: ä¸‹è½½ä¸­...")

    # æ£€æŸ¥ FFmpeg
    print("\nğŸ” æ£€æŸ¥ FFmpeg")
    import shutil
    if shutil.which("ffmpeg"):
        print(f"  âœ… FFmpeg: å·²å®‰è£…")
    else:
        print(f"  âŒ FFmpeg: æœªæ‰¾åˆ°")

    # æ£€æŸ¥ Python åŒ…
    print("\nğŸ” æ£€æŸ¥ Python åŒ…")
    packages = ["funasr", "modelscope", "whisper", "torchaudio"]
    for pkg in packages:
        try:
            __import__(pkg)
            print(f"  âœ… {pkg}")
        except ImportError:
            print(f"  âŒ {pkg}")

    print("\n" + "=" * 60)

if __name__ == "__main__":
    check_installation()
